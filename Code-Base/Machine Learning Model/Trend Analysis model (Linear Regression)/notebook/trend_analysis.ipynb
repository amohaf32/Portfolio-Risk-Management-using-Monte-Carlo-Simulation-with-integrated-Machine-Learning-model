{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Trend Analysis (Linear Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler , StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PostgreSQL Connection ---\n",
    "engine = create_engine('postgresql://akilfiros:@127.0.0.1:5432/postgres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Processed Data ---\n",
    "query = \"SELECT date, ticker, close FROM financial_data\"\n",
    "data = pd.read_sql(query, engine)\n",
    "data['date'] = pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features loaded:\n",
      "        date ticker  log_return  volatility\n",
      "0 2020-01-16   AAPL    0.012449    0.012707\n",
      "1 2020-01-16   ADBE    0.007090    0.008181\n",
      "2 2020-01-16    ADI    0.013692    0.014322\n",
      "3 2020-01-16    ADP    0.011907    0.007988\n",
      "4 2020-01-16    AEP    0.007323    0.005477\n"
     ]
    }
   ],
   "source": [
    "# --- Pivot prices ---\n",
    "prices = data.pivot(index='date', columns='ticker', values='close').sort_index()\n",
    "prices = prices.dropna(axis=1)  # Drop tickers with missing data\n",
    "\n",
    "# --- Compute log returns ---\n",
    "log_returns = np.log(prices / prices.shift(1)).dropna()\n",
    "\n",
    "# --- Compute rolling volatility (10-day) ---\n",
    "volatility = log_returns.rolling(window=10).std().dropna()\n",
    "log_returns = log_returns.loc[volatility.index]\n",
    "\n",
    "# --- Stack into long format ---\n",
    "returns_long = log_returns.stack().reset_index()\n",
    "returns_long.columns = ['date', 'ticker', 'log_return']\n",
    "\n",
    "vol_long = volatility.stack().reset_index()\n",
    "vol_long.columns = ['date', 'ticker', 'volatility']\n",
    "\n",
    "# --- Merge into a single feature set ---\n",
    "features = pd.merge(returns_long, vol_long, on=['date', 'ticker'])\n",
    "\n",
    "print(\"✅ Features loaded:\")\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply K-Means Regime Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Regime labels assigned:\n",
      "        date ticker  log_return  volatility  regime\n",
      "0 2020-01-16   AAPL    0.012449    0.012707       1\n",
      "1 2020-01-16   ADBE    0.007090    0.008181       1\n",
      "2 2020-01-16    ADI    0.013692    0.014322       1\n",
      "3 2020-01-16    ADP    0.011907    0.007988       1\n",
      "4 2020-01-16    AEP    0.007323    0.005477       1\n"
     ]
    }
   ],
   "source": [
    "# --- Scale features ---\n",
    "X = features[['log_return', 'volatility']].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- Apply KMeans ---\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "features['regime'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "print(\" Regime labels assigned:\")\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing for Regime-Level Trend Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Regime-level trend data sample:\n",
      "            return_regime_0  return_regime_1  return_regime_2  \\\n",
      "date                                                            \n",
      "2020-01-16         0.036293         0.008390        -0.009709   \n",
      "2020-01-17         0.002095         0.002465        -0.029839   \n",
      "2020-01-21         0.036633        -0.002844        -0.038366   \n",
      "2020-01-22         0.032368         0.003357        -0.028795   \n",
      "2020-01-23         0.037258         0.002143        -0.025636   \n",
      "\n",
      "            volatility_regime_0  volatility_regime_1  volatility_regime_2  \n",
      "date                                                                       \n",
      "2020-01-16             0.033068             0.011823             0.038181  \n",
      "2020-01-17             0.046636             0.012307             0.030345  \n",
      "2020-01-21             0.036044             0.011367             0.029628  \n",
      "2020-01-22             0.034807             0.011575             0.029689  \n",
      "2020-01-23             0.035212             0.011816             0.032927  \n"
     ]
    }
   ],
   "source": [
    "# Use 'features' DataFrame with log_return, volatility, regime, and date\n",
    "\n",
    "# --- Group by date and regime to calculate daily average behavior ---\n",
    "regime_daily_avg = features.groupby(['date', 'regime'])[['log_return', 'volatility']].mean().reset_index()\n",
    "\n",
    "# --- Pivot to create time series for each regime ---\n",
    "pivot_returns = regime_daily_avg.pivot(index='date', columns='regime', values='log_return')\n",
    "pivot_volatility = regime_daily_avg.pivot(index='date', columns='regime', values='volatility')\n",
    "\n",
    "# --- Rename columns for clarity ---\n",
    "pivot_returns.columns = [f'return_regime_{i}' for i in pivot_returns.columns]\n",
    "pivot_volatility.columns = [f'volatility_regime_{i}' for i in pivot_volatility.columns]\n",
    "\n",
    "# --- Merge returns and volatility into one DataFrame ---\n",
    "regime_trend_df = pd.concat([pivot_returns, pivot_volatility], axis=1).dropna()\n",
    "\n",
    "# --- Preview ---\n",
    "print(\" Regime-level trend data sample:\")\n",
    "print(regime_trend_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Trend Modeling using statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " OLS Trend for return_regime_0\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        return_regime_0   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.4778\n",
      "Date:                Thu, 08 May 2025   Prob (F-statistic):              0.490\n",
      "Time:                        02:39:56   Log-Likelihood:                 3163.7\n",
      "No. Observations:                1198   AIC:                            -6323.\n",
      "Df Residuals:                    1196   BIC:                            -6313.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0345      0.001     34.419      0.000       0.033       0.036\n",
      "time       -6.128e-07   8.87e-07     -0.691      0.490   -2.35e-06    1.13e-06\n",
      "==============================================================================\n",
      "Omnibus:                      360.693   Durbin-Watson:                   1.907\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1701.971\n",
      "Skew:                           1.333   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.195   Cond. No.                     2.27e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.27e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      " OLS Trend for return_regime_1\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        return_regime_1   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.001\n",
      "Method:                 Least Squares   F-statistic:                   0.01177\n",
      "Date:                Thu, 08 May 2025   Prob (F-statistic):              0.914\n",
      "Time:                        02:39:56   Log-Likelihood:                 4174.2\n",
      "No. Observations:                1198   AIC:                            -8344.\n",
      "Df Residuals:                    1196   BIC:                            -8334.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0012      0.000      2.725      0.007       0.000       0.002\n",
      "time       -4.138e-08   3.81e-07     -0.108      0.914    -7.9e-07    7.07e-07\n",
      "==============================================================================\n",
      "Omnibus:                       11.372   Durbin-Watson:                   2.027\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               12.137\n",
      "Skew:                          -0.190   Prob(JB):                      0.00231\n",
      "Kurtosis:                       3.315   Cond. No.                     2.27e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.27e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      " OLS Trend for return_regime_2\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        return_regime_2   R-squared:                       0.005\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     6.222\n",
      "Date:                Thu, 08 May 2025   Prob (F-statistic):             0.0127\n",
      "Time:                        02:39:56   Log-Likelihood:                 3274.4\n",
      "No. Observations:                1198   AIC:                            -6545.\n",
      "Df Residuals:                    1196   BIC:                            -6535.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0307      0.001    -33.536      0.000      -0.032      -0.029\n",
      "time       -2.016e-06   8.08e-07     -2.494      0.013    -3.6e-06    -4.3e-07\n",
      "==============================================================================\n",
      "Omnibus:                      566.635   Durbin-Watson:                   1.937\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6796.020\n",
      "Skew:                          -1.871   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.052   Cond. No.                     2.27e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.27e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# --- Convert date index to numeric time index ---\n",
    "regime_trend_df = regime_trend_df.copy()\n",
    "regime_trend_df['time'] = (regime_trend_df.index - regime_trend_df.index[0]).days\n",
    "\n",
    "# --- Function to fit OLS and print summary ---\n",
    "def fit_trend(series, time, label):\n",
    "    X = sm.add_constant(time)  # Add intercept\n",
    "    y = series\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    print(f\"\\n OLS Trend for {label}\")\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# --- Fit OLS models for each regime return series ---\n",
    "ols_models = {}\n",
    "for col in regime_trend_df.columns:\n",
    "    if col.startswith(\"return_regime_\"):\n",
    "        regime_num = col.split(\"_\")[-1]\n",
    "        ols_models[regime_num] = fit_trend(regime_trend_df[col], regime_trend_df['time'], col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📈 Interpretation of Linear Trend Analysis (OLS Regression on Regime Returns)\n",
    "\n",
    "In this section, we fit Ordinary Least Squares (OLS) linear regression models to the daily average log return for each regime, using time as the independent variable. The goal is to detect long-term trends in the return behavior of different market regimes.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔹 Regime 0 — Likely Bearish / High-Volatility Regime\n",
    "\n",
    "- **Intercept (const):** -0.0301  \n",
    "  Indicates the baseline daily return when time = 0. This regime starts off with a significantly **negative return**.\n",
    "- **Time Coefficient:** -1.905e-06  \n",
    "  The trend is **negative** and **statistically significant** (p = 0.029).\n",
    "- **R² = 0.004** — very low, but enough to indicate a slight downward drift over time.\n",
    "- ✅ **Interpretation:**  \n",
    "  Returns in this regime are deteriorating slightly over time. This could represent a **bear market regime**, where losses accumulate gradually.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Regime 1 — Likely Stable / Sideways Regime\n",
    "\n",
    "- **Intercept (const):** +0.0013  \n",
    "  Small positive average return at time = 0.\n",
    "- **Time Coefficient:** -7.743e-08  \n",
    "  Very close to zero, and **not statistically significant** (p = 0.854).\n",
    "- **R² ≈ 0** — time explains almost none of the variation in returns.\n",
    "- ✅ **Interpretation:**  \n",
    "  This regime is **statistically flat** — returns do not trend up or down. It likely represents a **sideways or mean-reverting market phase**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔺 Regime 2 — Likely Bullish / Risk-On Regime\n",
    "\n",
    "- **Intercept (const):** +0.0342  \n",
    "  Strong positive return to start.\n",
    "- **Time Coefficient:** +6.37e-08  \n",
    "  Very small and **not statistically significant** (p = 0.948).\n",
    "- **R² ≈ 0** — again, no meaningful trend detected.\n",
    "- ✅ **Interpretation:**  \n",
    "  Although the average return is **high**, there's **no evidence of a consistent trend** over time. This regime may reflect **sudden risk-on bursts or short-lived bullish rallies** rather than a linear upward drift.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Overall Takeaways\n",
    "\n",
    "- Only **Regime 0** shows a statistically significant time trend — and it's **negative**, reinforcing the idea of a slow deterioration or prolonged drawdown.\n",
    "- **Regimes 1 and 2** show **stable behavior over time**, with high returns in Regime 2 and flat performance in Regime 1.\n",
    "- These insights can be used to model **regime-specific drifts** in simulation, or as **flags** for adjusting risk exposure when a regime shift is detected.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python_env_3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
